?read
q1.dat <- readRDS("q1dat.rds")
str(q1.dat)
# Input your answer here
plot(Y ~ X, data = q1.dat)
# Input your answer here
q1.lm <- lm(Y ~ X, data = q3.dat)
# Input your answer here
q1.lm <- lm(Y ~ X, data = q1.dat)
q1.lm.coefs <- coef(q1.lm)
q1.lm.sigma <- sigma(q1.lm)
plot(Y ~ X, data = q1.dat)
abline(q1.lm)
?transform
?lines
# Input your answer here
negLaplaceLikelihood <- function(beta0, beta1, sigma)
{
Y <- q1.dat[["Y"]]
X <- q1.dat[["X"]]
if (sigma < 0) return(Inf)
length(X) * log(2 * sigma) + sum(abs(Y - beta0 - beta1 * X))/sigma
}
q1.lm
?mle
# Input your answer here
starting.point <- list(beta0 = q1.lm.coefs[1], beta1 = q1.lm.coefs[2], sigma = q1.lm.sigma)
mle.estimates <- stats4::mle(negLaplaceLikelihood, starting.point)
mle.coef <- mle.estimates@coef
matrix(c(q1.lm.coefs, q3.lm.sigma, mle.coef), nrow = 2, byrow = TRUE,
dimnames = list(c("Least Squares", "MLE"), c("beta0", "beta1", "sigma")))
# Input your answer here
starting.point <- list(beta0 = q1.lm.coefs[1], beta1 = q1.lm.coefs[2], sigma = q1.lm.sigma)
mle.estimates <- stats4::mle(negLaplaceLikelihood, starting.point)
mle.coef <- mle.estimates@coef
matrix(c(q1.lm.coefs, q1.lm.sigma, mle.coef), nrow = 2, byrow = TRUE,
dimnames = list(c("Least Squares", "MLE"), c("beta0", "beta1", "sigma")))
mle.coef
?abline
encoded.data <- readRDS("encoded.data.rds")
View(encoded.data)
View(encoded.data)
# Input your answer here
encoded.data.without.labels <- encoded.data[-11]
dim(encoded.data.without.labels)
View(encoded.data)
View(encoded.data)
# Input your answer here
pca <- prcomp(encode.data.without.labels, scale = TRUE)
# Input your answer here
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
type.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = types)
# Input your answer here
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
type.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = type)
knitr::opts_chunk$set(echo = TRUE)
authors
# Input your answer here
types <- factor(encoded.data[[-1]])
# Input your answer here
types <- factor(encoded.data[[11]])
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
type.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = types)
pca.plot <- ggplot(type.df, aes(PC1, PC2, col = types)) + geom_points() + theme_minimal()
# Input your answer here
types <- factor(encoded.data[[11]])
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
library(ggplot2)
type.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = types)
pca.plot <- ggplot(type.df, aes(PC1, PC2, col = types)) + geom_points() + theme_minimal()
# Input your answer here
types <- factor(encoded.data[[11]])
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
library(ggplot2)
type.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = types)
pca.plot <- ggplot(type.df, aes(PC1, PC2, col = types)) + geom_points() + theme_minimal()
# Input your answer here
types <- factor(encoded.data[[11]])
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
library(ggplot2)
library(tidyr)
type.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = types)
pca.plot <- ggplot(type.df, aes(PC1, PC2, col = types)) + geom_points() + theme_minimal()
library(ggplot2)
# Input your answer here
types <- factor(encoded.data[[11]])
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
library(ggplot2)
ptype.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = types)
pca.plot <- ggplot(tye.df, aes(PC1, PC2, col = types)) + geom_point() + theme_minimal()
# Input your answer here
types <- factor(encoded.data[[11]])
pca <- prcomp(encoded.data.without.labels, scale = TRUE)
library(gridExtra)
library(ggplot2)
type.df <- data.frame(PC1 = pca$x[,1], PC2 = pca$x[,2], labels = types)
pca.plot <- ggplot(type.df, aes(PC1, PC2, col = types)) + geom_point() + theme_minimal()
pca.plot
# Input your answer here
variance.explained <- pca$sdev^2
cumulative.variance <- cumsum(prop.table(pca$sdev^2) * 100)
plot(1:10, cumulative.variance, xlab = "Number of components", ylab = "Cumulative variance explained (%)", type = 'l')
abline(h = 80, lty = 'dotted')
abline(v = 5, lty = 'dashed')
# Input your answer here
variance.explained <- pca$sdev^2
cumulative.variance <- cumsum(prop.table(pca$sdev^2) * 100)
plot(1:10, cumulative.variance, xlab = "Number of components", ylab = "Cumulative variance explained (%)", type = 'l')
abline(h = 80, lty = 'dotted')
# Input your answer here
variance.explained <- pca$sdev^2
cumulative.variance <- cumsum(prop.table(pca$sdev^2) * 100)
plot(1:10, cumulative.variance, xlab = "Number of components", ylab = "Cumulative variance explained (%)", type = 'l')
abline(h = 80, lty = 'dotted')
abline(v = 5, lty = 'dashed')
?loess
?lines
covid <- readRDS("covid-data.rds")
# Input your answer here
str(covid)
# Input your answer here
covid <- transform(covid, NSW_and_VIC = NSW + VIC)
head(covid)
# Input your answer here
plot(covid, ty = 'l', xlab = "Time", ylab = "Number of cases", main = "Covid cases in NSW and VIC")
?matplot
# Input your answer here
matplot(covid, ty = 'l', xlab = "Time", ylab = "Number of cases", main = "Covid cases in NSW and VIC")
legend("topleft", legend = colnames(covid), col = 1:3, lty = 1:3)
?lowess
# Input your answer here
matplot(covid, ty = 'l', xlab = "Time", ylab = "Number of cases", main = "Covid cases in NSW and VIC")
lines(lowess(covid[[3]], f = 0.5), col="blue")
legend("topleft", legend = c(colnames(covid), "Smoother of NSW and VIC"), col = c(1:3, "blue"), lty = c(1:3, 1))
# Input your answer here
matplot(covid, ty = 'l', xlab = "Time", ylab = "Number of cases", main = "Covid cases in NSW and VIC")
lines(lowess(covid[[3]], f = 0.25), col="blue")
legend("topleft", legend = c(colnames(covid), "Smoother of NSW and VIC"), col = c(1:3, "blue"), lty = c(1:3, 1))
# Input your answer here
matplot(covid, ty = 'l', xlab = "Time", ylab = "Number of cases", main = "Covid cases in NSW and VIC")
lines(lowess(covid[[3]], f = 0.025), col="blue")
legend("topleft", legend = c(colnames(covid), "Smoother of NSW and VIC"), col = c(1:3, "blue"), lty = c(1:3, 1))
library(mlbench)
SID <- <insert SID here># INSERT YOUR SID AS AN INTEGER HERE
library(mlbench)
SID <- 500201059
set.seed(500201059)
simulated.data <- mlbench.2dnormals(n = 500, sd = 2)
q2.dat <- as.data.frame(simulated.data)
# Input your answer here
?mlbench.2dnormals
q2.dat
?predict
# Input your answer here
full.logit.model <- glm(classes ~ ., data = q2.dat, family = binomial(link = "logit"))
summary(full.logit.model)
log.predictions <- predict(full.logit.model, newdata = q2.dat, type = "response")
predictions <- ifelse(log.predictions > 0.5, 2, 1)
accuracy <- mean(predictions == q2.dat$classes)
accuracy
plot(x.2 ~ x.1, data = q2.dat, col = classes)
betas <- coef(full.logit.model)
abline(a = -betas[1]/betas[3], b = -betas[2]/betas[3], lty = "dotted")
betas
set.seed(5003)
# Input your answer here
fold <- createFolds(q2.dat$classes, k = 5)
library(lattice)
library(ggpot2)
library(lattice)
library(ggplot2)
set.seed(5003)
# Input your answer here
fold <- createFolds(q2.dat$classes, k = 5)
library(lattice)
library(ggplot2)
library(caret)
set.seed(5003)
# Input your answer here
fold <- createFolds(q2.dat$classes, k = 5)
data(BostonHousing, package = "mlbench")
q3.dat <- subset(BostonHousing, select = c("medv", "lstat", "rm"))
# Input your answer here
View(BostonHousing)
View(BostonHousing)
?paris
??pairs
data(BostonHousing, package = "mlbench")
q3.dat <- subset(BostonHousing, select = c("medv", "lstat", "rm"))
dim(q3.dat)
pairs(q3.dat)
# Input your answer here
# Input your answer here
simple.lm <- lm(medv ~ rm + lstat, data = q3.dat)
lm.coefs <- coef(simple.lm)
lm.sigma <- sigma(simple.lm)
lm.estimates <- c(lm.coefs, lm.sigma)
lm.estimates
# Input your answer here
n <- nrow(q3.dat)
y <- q3.dat[["medv"]]
x1 <- q3.dat[["rm"]]
x2 <- q3.dat[["lstat"]]
negLogLikelihood <- function(beta0 = 0, beta1 = 0, beta2 = 0, sigma = 1) {
if (sigma < 0)
return(Inf)
else
out <- n/2 * log(2 * pi) + n * log(sigma) + 1/(2 * sigma^2) * sum((y - beta0 - beta1 * x1 - beta2 * x2)^2)
out
}
# Input your answer here
n <- nrow(q3.dat)
y <- q3.dat[["medv"]]
x1 <- q3.dat[["rm"]]
x2 <- q3.dat[["lstat"]]
negLogLikelihood <- function(beta0, beta1, beta2, sigma) {
if (sigma < 0)
return(Inf)
else
out <- n/2 * log(2 * pi) + n * log(sigma) + 1/(2 * sigma^2) * sum((y - beta0 - beta1 * x1 - beta2 * x2)^2)
out
}
ï¼Ÿmle
?mle
vic.delta.wave <- readRDS("S2-2021-Q1-vic-delta-wave.rds")
nsw.delta.wave <- readRDS("S2-2021-Q1-nsw-delta-wave.rds")
str(vic.delta.wave)
str(nsw.delta.wave)
dim(vic.delta.wave)
dim(nsw.delta.wave)
View(nsw.delta.wave)
View(vic.delta.wave)
View(vic.delta.wave)
lockvic.dat <- subset(vic.delta.wave, select = date > as.Date("2021-08-05"))
View(lockvic.dat)
lockvic.dat <- subset(vic.delta.wave, date > as.Date("2021-08-05"))
View(lockvic.dat)
View(lockvic.dat)
lockvic.dat <- subset(vic.delta.wave, date > as.Date("2021-08-05"))
locknsw.dat <- subset(nsw.delta.wave, date > as.Date("2021-06-26"))
View(locknsw.dat)
View(locknsw.dat)
View(locknsw.dat)
View(locknsw.dat)
View(lockvic.dat)
View(lockvic.dat)
lockvic.dat <- subset(vic.delta.wave, date > as.Date("2021-08-05"))
locknsw.dat <- subset(nsw.delta.wave, date > as.Date("2021-06-26"))
dim(lockvic.dat)
dim(locknsw.dat)
lockvic.dat <- subset(vic.delta.wave, date > as.Date("2021-08-04"))
locknsw.dat <- subset(nsw.delta.wave, date > as.Date("2021-06-25"))
dim(lockvic.dat) #47 days for the latest lockdown
dim(locknsw.dat) #87 days for the latest lockdown
View(locknsw.dat)
View(locknsw.dat)
View(lockvic.dat)
View(lockvic.dat)
lockdown.days.vic <- transform(lockvic.dat, days.in.lockdown = date - as.Date("2021-08-05"))
lockdown.days.nsw <- transform(locknsw.dat, days.in.lockdown = date - as.Date("2021-06-26"))
View(lockdown.days.nsw)
lockdown.days.vic <- transform(lockvic.dat, days.in.lockdown = date - as.Date("2021-08-05"))
lockdown.days.nsw <- transform(locknsw.dat, days.in.lockdown = date - as.Date("2021-06-26"))
lockdown.state.vic <- transform(lockdown.days.vic, state = "VIC")
lockdown.state.nsw <- transform(lockdown.days.nsw, state = "NSW")
View(lockdown.days.nsw)
View(lockdown.days.nsw)
View(lockdown.state.nsw)
View(lockdown.state.nsw)
?rbind
lockdown.comb <- rbind(lockdown.state.vic,lockdown.state.nsw)
View(lockdown.comb)
View(lockdown.comb)
dim(lockdown.comb)
lockdown.comb <- as.data.frame(rbind(lockdown.state.vic,lockdown.state.nsw))
View(lockdown.comb)
View(lockdown.comb)
View(lockdown.comb)
View(lockdown.comb)
plot(confirmed ~ days.in.lockdown, data = lockdown.comb)
plot(confirmed ~ days.in.lockdown, data = lockdown.comb)
matplot(lockdown.comb, ty = 'l', xlab = "the days in the latest lockdown", ylab = "Number of cases", main = "Covid cases in NSW and VIC")
lines(lowess(lockdown.comb[[4]], f = 0.025), col="blue")
legend("topleft", legend = c(colnames(lockdown.comb), "Smoother of NSW and VIC"), col = c(1:3, "blue"), lty = c(1:3, 1))
lockdown.comb <- as.data.frame(rbind(lockdown.state.vic,lockdown.state.nsw,by="date"))
lockdown.comb <- as.data.frame(merge(lockdown.state.vic,lockdown.state.nsw,by="date"))
View(lockdown.comb)
lockdown.comb <- as.data.frame(rbind(lockdown.state.vic,lockdown.state.nsw))
View(lockdown.comb)
View(lockdown.comb)
q2.dat <- readRDS("S2-2021-Q2.rds")
View(q2.dat)
View(q2.dat)
plot(confirmed ~ days.in.lockdown, data = q2.dat)
plot(confirmed ~ days.in.lockdown, data = q2.dat)
abline(q2.dat)
plot(confirmed ~ days.in.lockdown, data = q2.dat)
q2.lm <- lm(confirmed ~ days.in.lockdown, data = q2.dat)
abline(q2.lm)
plot(confirmed ~ days.in.lockdown, data = q2.dat)
q2.lm <- lm(confirmed ~ days.in.lockdown, data = q2.dat)
abline(q2.lm)
q2.lm.coefs <- coef(q2.lm)
summary(q2.lm)
lda.model <- readRDS('S2-2021-Q3-lda-model.rds')
svm.model <- readRDS('S2-2021-Q3-svm-model.rds')
test.data <- readRDS('S2-2021-Q3-test-data.rds')
View(lda.model)
View(lda.model)
View(test.data)
View(test.data)
View(lda.model)
View(svm.model)
lda.pred <- predict(lda.model, newdata = test.data)
lda.confusion <- confusionMatrix(lda.pred, test.data$Will.recommend)
lda.pred <- predict(lda.model, newdata = test.data)
lda.confusion <- confusionMatrix(table(lda.pred, test.data$Will.recommend))
View(lda.model)
lda.model
lda.pred <- predict(lda.model, newdata = test.data)
lda.pred
svm.pred <- predict(svm.model, newdata = test.data)
svm.pred <- predict(svm.model, newdata = test.data)
lda.pred <- predict(lda.model, newdata = test.data)
svm.pred <- predict(svm.model, newdata = test.data)
lda.pred <- predict(lda.model, newdata = test.data)
svm.pred <- predict(svm.model, newdata = test.data)
metrics <- lapply(fitted.models, function(mod) {
predictions <- predict(mod, newdata = test.data)
confusionMatrix(predictions, test.data$Will.recommend)
})
lda.pred <- predict(lda.model, newdata = test.data)
svm.pred <- predict(svm.model, newdata = test.data)
lda.pred <- predict(lda.model, newdata = test.data)
svm.pred <- predict(svm.model, newdata = test.data)
lda.confusion <- confusionMatrix(lda.pred, test.data$Will.recommend)
lda.pred <- predict(lda.model, newdata = test.data)
lda.pred <- predict(lda.model, newdata = test.data)
lda.confusion <- confusionMatrix(lda.pred, test.data$Will.recommend)
library(caret)
library(stats)
library(e1071)
lda.pred <- predict(lda.model, newdata = test.data)
lda.confusion <- confusionMatrix(lda.pred, test.data$Will.recommend)
library(lattice)
library(ggplot2)
library(caret)
library(stats)
library(e1071)
lda.pred <- predict(lda.model, newdata = test.data)
lda.confusion <- confusionMatrix(lda.pred, test.data$Will.recommend)
lda.pred <- predict(lda.model, newdata = table(test.data))
lda.pred <- predict(lda.model, newdata = test.data)
lda.confusion <- confusionMatrix(lda.pred, test.data$Will.recommend)
?predict
class(newdata)
class(test.data)
lda.pred <- predict(table(lda.model), newdata = test.data)
class(lda.model)
data(PimaIndiansDiabetes2, package = "mlbench")
str(PimaIndiansDiabetes2)
library(lattice)
library(ggplot2)
library(caret)
library(dplyr)
library(tidyr)
set.seed(5003)
inTrain <- createDataPartition(complete.pima$diabetes, p = .75)[[1]]
data(PimaIndiansDiabetes2, package = "mlbench")
str(PimaIndiansDiabetes2)
logit.model <- glm(diabetes ~ ., data = PimaIndiansDiabetes2,
family = binomial(link = 'logit'))
summary(logit.model)
predictors <- names(PimaIndiansDiabetes2)[-9]
sapply(predictors,
function(x) summary(glm(as.formula(paste0("diabetes ~ ", x)),
family = binomial(link = "logit"),
data = PimaIndiansDiabetes2))$coefficients[2, 4])
install.packages("tidyr")
library(magrittr)
library(tidyr)
logit.decision <- ifelse(logit.model$fitted.values > 0.5, "pos", "neg")
complete.pima <- PimaIndiansDiabetes2 %>% drop_na
#calculate the number that they are equal
logit.accuracy <- mean(logit.decision == complete.pima$diabetes, na.rm = TRUE) * 100
logit.accuracy
#alternative: table(complete.pima$diabetes,logit.decision),then accuracy= all true/all
install.packages("tidyr")
library(lattice)
library(ggplot2)
library(caret)
library(dplyr)
library(tidyr)
set.seed(5003)
inTrain <- createDataPartition(complete.pima$diabetes, p = .75)[[1]]
pimatrain <- complete.pima[ Train_data, ]
data(PimaIndiansDiabetes2, package = "mlbench")
str(PimaIndiansDiabetes2)
# 1)Logistic regression
logit.model <- train(diabetes ~ . , data = pimatrain, method = "glm",
family = binomial(link = 'logit'),
trControl = trainControl(method = "repeatedcv", repeats = 5))
library(lattice)
library(ggplot2)
library(caret)
library(dplyr)
library(tidyr)
set.seed(5003)
inTrain <- createDataPartition(complete.pima$diabetes, p = .75)[[1]]
pimatrain <- complete.pima[ inTrain_data, ]
library(lattice)
library(ggplot2)
library(caret)
library(dplyr)
library(tidyr)
set.seed(5003)
inTrain <- createDataPartition(complete.pima$diabetes, p = .75)[[1]]
pimatrain <- complete.pima[ inTrain, ]
pimatest  <- complete.pima[-inTrain, ]
head(inTrain)
nrow(pimatrain)
nrow(pimatest)
# 1)Logistic regression
logit.model <- train(diabetes ~ . , data = pimatrain, method = "glm",
family = binomial(link = 'logit'),
trControl = trainControl(method = "repeatedcv", repeats = 5))
logit.model
# 2)LDA
lda.model <- train(diabetes ~ . , data = pimatrain, method = "lda",
trControl = trainControl(method = "repeatedcv", repeats = 5))
lda.model
# 3)knn
knn.model <- train(diabetes ~ . , data = pimatrain, method = "knn",
trControl = trainControl(method = "repeatedcv", repeats = 5))
knn.model
# 4)svm
svm.model <- train(diabetes ~ ., data = pimatrain, method = "svmLinearWeights",
trControl = trainControl(method = "repeatedcv", repeats = 5))
svm.model
class(lda.model)
class(logit.model)
class(pimatest)
class(lda.model)
class(test.data)
class(predict)
class(test.data$Will.recommend)
lda.pred <- talbe(predict(lda.model),test.data)
class(logit.pred)
class(lda.pred)
